{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0908_heri002",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heriswn/LatihanDTS/blob/master/0908_heri002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh3wY0uGF2gA",
        "colab_type": "text"
      },
      "source": [
        "## PreProsessing\n",
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tit0UHNH74Av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "89d6b7ea-516b-4c8b-8947-96e67315e9ab"
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7QcxddQFnnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "93ad698f-2dd4-40f9-af03-09562b54dfcd"
      },
      "source": [
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        "print(tagged_sentences[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_SDIrEFy53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features(sentence, index):\n",
        "  \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
        "  return {\n",
        "      'word': sentence[index],\n",
        "      'is_first': index == 0,\n",
        "      'is_last': index==len(sentence) - 1,\n",
        "      'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "      'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "      'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "      'prefix-1': sentence[index][0],\n",
        "      'prefix-2': sentence[index][:2],\n",
        "      'prefix-3': sentence[index][:3],\n",
        "      'suffix-1': sentence[index][-1],\n",
        "      'suffix-2': sentence[index][-2:],\n",
        "      'suffix-3': sentence[index][-3:],\n",
        "      'prev_word': '' if index == 0 else sentence[index -1],\n",
        "      'prev_2word': '' if (index == 0) or (index == 1) else sentence[index -2],\n",
        "      'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "      'next_2word': '' if index >= len(sentence) - 2 else sentence[index +2],\n",
        "      'has_hyphen': '-' in sentence[index],\n",
        "      'is_numeric': sentence[index].isdigit(),\n",
        "      'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv4fI8LkLNoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tag.util import untag\n",
        "\n",
        "cutoff = int(.75 * len(tagged_sentences))\n",
        "training_sentences = tagged_sentences[:cutoff]\n",
        "test_sentences = tagged_sentences[cutoff:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itPM2ojfIIGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_to_dataset(tagged_sentences):\n",
        "  X, y = [], []\n",
        "  \n",
        "  for tagged in tagged_sentences:\n",
        "    X.append([features(untag(tagged), index) for index in range(len(tagged))])\n",
        "    y.append([tag for _, tag in tagged])\n",
        "    \n",
        "  return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3SCeQB2LWki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = transform_to_dataset(training_sentences)\n",
        "X_test, y_test = transform_to_dataset(test_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMLrGwEJLSOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "24f73f3c-c7a8-483b-9b8e-47e4a69e690b"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2935\n",
            "979\n",
            "[{'word': 'Pierre', 'is_first': True, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'P', 'prefix-2': 'Pi', 'prefix-3': 'Pie', 'suffix-1': 'e', 'suffix-2': 're', 'suffix-3': 'rre', 'prev_word': '', 'prev_2word': '', 'next_word': 'Vinken', 'next_2word': ',', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Vinken', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'V', 'prefix-2': 'Vi', 'prefix-3': 'Vin', 'suffix-1': 'n', 'suffix-2': 'en', 'suffix-3': 'ken', 'prev_word': 'Pierre', 'prev_2word': '', 'next_word': ',', 'next_2word': '61', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': 'Vinken', 'prev_2word': 'Pierre', 'next_word': '61', 'next_2word': 'years', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '61', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '6', 'prefix-2': '61', 'prefix-3': '61', 'suffix-1': '1', 'suffix-2': '61', 'suffix-3': '61', 'prev_word': ',', 'prev_2word': 'Vinken', 'next_word': 'years', 'next_2word': 'old', 'has_hyphen': False, 'is_numeric': True, 'capitals_inside': False}, {'word': 'years', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'y', 'prefix-2': 'ye', 'prefix-3': 'yea', 'suffix-1': 's', 'suffix-2': 'rs', 'suffix-3': 'ars', 'prev_word': '61', 'prev_2word': ',', 'next_word': 'old', 'next_2word': ',', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'old', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'o', 'prefix-2': 'ol', 'prefix-3': 'old', 'suffix-1': 'd', 'suffix-2': 'ld', 'suffix-3': 'old', 'prev_word': 'years', 'prev_2word': '61', 'next_word': ',', 'next_2word': 'will', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': 'old', 'prev_2word': 'years', 'next_word': 'will', 'next_2word': 'join', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'will', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'w', 'prefix-2': 'wi', 'prefix-3': 'wil', 'suffix-1': 'l', 'suffix-2': 'll', 'suffix-3': 'ill', 'prev_word': ',', 'prev_2word': 'old', 'next_word': 'join', 'next_2word': 'the', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'join', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'j', 'prefix-2': 'jo', 'prefix-3': 'joi', 'suffix-1': 'n', 'suffix-2': 'in', 'suffix-3': 'oin', 'prev_word': 'will', 'prev_2word': ',', 'next_word': 'the', 'next_2word': 'board', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'the', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 't', 'prefix-2': 'th', 'prefix-3': 'the', 'suffix-1': 'e', 'suffix-2': 'he', 'suffix-3': 'the', 'prev_word': 'join', 'prev_2word': 'will', 'next_word': 'board', 'next_2word': 'as', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'board', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'b', 'prefix-2': 'bo', 'prefix-3': 'boa', 'suffix-1': 'd', 'suffix-2': 'rd', 'suffix-3': 'ard', 'prev_word': 'the', 'prev_2word': 'join', 'next_word': 'as', 'next_2word': 'a', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'as', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'as', 'prefix-3': 'as', 'suffix-1': 's', 'suffix-2': 'as', 'suffix-3': 'as', 'prev_word': 'board', 'prev_2word': 'the', 'next_word': 'a', 'next_2word': 'nonexecutive', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'a', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'a', 'prefix-3': 'a', 'suffix-1': 'a', 'suffix-2': 'a', 'suffix-3': 'a', 'prev_word': 'as', 'prev_2word': 'board', 'next_word': 'nonexecutive', 'next_2word': 'director', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'nonexecutive', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'n', 'prefix-2': 'no', 'prefix-3': 'non', 'suffix-1': 'e', 'suffix-2': 've', 'suffix-3': 'ive', 'prev_word': 'a', 'prev_2word': 'as', 'next_word': 'director', 'next_2word': 'Nov.', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'director', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'd', 'prefix-2': 'di', 'prefix-3': 'dir', 'suffix-1': 'r', 'suffix-2': 'or', 'suffix-3': 'tor', 'prev_word': 'nonexecutive', 'prev_2word': 'a', 'next_word': 'Nov.', 'next_2word': '29', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Nov.', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'N', 'prefix-2': 'No', 'prefix-3': 'Nov', 'suffix-1': '.', 'suffix-2': 'v.', 'suffix-3': 'ov.', 'prev_word': 'director', 'prev_2word': 'nonexecutive', 'next_word': '29', 'next_2word': '.', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '29', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '2', 'prefix-2': '29', 'prefix-3': '29', 'suffix-1': '9', 'suffix-2': '29', 'suffix-3': '29', 'prev_word': 'Nov.', 'prev_2word': 'director', 'next_word': '.', 'next_2word': '', 'has_hyphen': False, 'is_numeric': True, 'capitals_inside': False}, {'word': '.', 'is_first': False, 'is_last': True, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '.', 'prefix-2': '.', 'prefix-3': '.', 'suffix-1': '.', 'suffix-2': '.', 'suffix-3': '.', 'prev_word': '29', 'prev_2word': 'Nov.', 'next_word': '', 'next_2word': '', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}]\n",
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaU-9fqOMF8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Xa88pRIlKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn_crfsuite import CRF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmduJ6szLnOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CRF()\n",
        "model.fit(X_train, y_train)\n",
        "from sklearn_crfsuite import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3r_6d7PTIby",
        "colab_type": "text"
      },
      "source": [
        "## Stop disini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR66hzzwN9f4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9e59c7d-74c6-4778-a95d-27ffdfa258ea"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(metrics.flat_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9602683593122289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI73_DBXRnyo",
        "colab_type": "text"
      },
      "source": [
        "### Delete prefix feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMrr4uXRODBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a343cf0-3928-433a-9963-13c053ec9f8c"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(metrics.flat_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9541619797525309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJJM6_l5TSm4",
        "colab_type": "text"
      },
      "source": [
        "### Add prev_2word and next_2word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--gSjFUpSNYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c90fd605-80e8-4f44-fc8c-072bfef7a49f"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(metrics.flat_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9611120038566607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLeUl_D1UqLX",
        "colab_type": "text"
      },
      "source": [
        "# NER with ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkqQJSi6TlcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8lSja6EVR5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "30c008cd-077b-43a4-b551-23aead40f115"
      },
      "source": [
        "df = pd.read_csv('ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
        "df = df[:1000000]\n",
        "df.head()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ULrTfyVjEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebf30091-c199-4495-f542-cb7508354e3c"
      },
      "source": [
        "df = df.fillna(method=\"ffill\")\n",
        "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45729, 34370, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSipF1Woa5gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "  \n",
        "  def __init__(self, data):\n",
        "    self.n_sent = 1\n",
        "    self.data = data\n",
        "    self.empy = False\n",
        "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
        "                                                      s['POS'].values.tolist(),\n",
        "                                                      s['Tag'].values.tolist())]\n",
        "    self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
        "    self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "  def get_next(self):\n",
        "    try:\n",
        "      s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "      self.n_sent += 1\n",
        "      return s\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "getter = SentenceGetter(df)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ej2BJ7cdQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "  word = sent[i][0]\n",
        "  postag = sent[i][0]\n",
        "  \n",
        "  features = {\n",
        "      'bias': 1.0,\n",
        "      'word.lower()': word.lower(),\n",
        "      'word[-3:]': word[-3:],\n",
        "      'word[-2:]': word[-2:],\n",
        "      'word.isupper()': word.isupper(),\n",
        "      'word.istitle()': word.istitle(),\n",
        "      'word.isdigit()': word.isdigit(),\n",
        "      'postag': postag,\n",
        "      'postag[:2]': postag[:2],\n",
        "  }\n",
        "  if i > 0:\n",
        "    word1 = sent[i-1][0]\n",
        "    postag1 = sent[i-1][1]\n",
        "    features.update({\n",
        "        '-1:word.lower()': word1.lower(),\n",
        "        '-1:word.istitle()': word1.istitle(),\n",
        "        '-1:word.isupper()': word1.isupper(),\n",
        "        '-1:postag': postag1,\n",
        "        '-1:postag[:2]': postag1[:2],\n",
        "    })\n",
        "  else:\n",
        "    features['BOS'] = True\n",
        "  if i < len(sent)-1:\n",
        "    word1 = sent[i+1][0]\n",
        "    postag1 = sent[i+1][1]\n",
        "    features.update({\n",
        "        '-1:word.lower()': word1.lower(),\n",
        "        '-1:word.istitle()': word1.istitle(),\n",
        "        '-1:word.isupper()': word1.isupper(),\n",
        "        '-1:postag': postag1,\n",
        "        '-1:postag[:2]': postag1[:2],        \n",
        "    })\n",
        "  else:\n",
        "    features['EOS'] = True\n",
        "  return features\n",
        "\n",
        "def sent2features(sent):\n",
        "  return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "  return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "  return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoSZRrMKfzTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [sent2features(s) for s in sentences]\n",
        "y = [sent2labels(s) for s in sentences]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnWnYk7QgQn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "6f7148ed-3b85-415c-a810-9392423486a4"
      },
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoMpgBpVhFap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "e64a144b-1373-44ea-e270-cbb93e4aaa05"
      },
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(y_test, y_pred))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.48      0.13      0.20       126\n",
            "       B-eve       0.62      0.45      0.52       100\n",
            "       B-geo       0.84      0.90      0.87     11755\n",
            "       B-gpe       0.96      0.93      0.94      5062\n",
            "       B-nat       0.59      0.38      0.46        58\n",
            "       B-org       0.78      0.70      0.74      6303\n",
            "       B-per       0.84      0.80      0.82      5341\n",
            "       B-tim       0.92      0.87      0.89      6329\n",
            "       I-art       0.23      0.03      0.05       101\n",
            "       I-eve       0.54      0.34      0.41        86\n",
            "       I-geo       0.80      0.78      0.79      2356\n",
            "       I-gpe       0.84      0.47      0.60        68\n",
            "       I-nat       1.00      0.35      0.52        23\n",
            "       I-org       0.77      0.79      0.78      5321\n",
            "       I-per       0.83      0.88      0.86      5351\n",
            "       I-tim       0.83      0.73      0.78      2031\n",
            "           O       0.99      0.99      0.99    278297\n",
            "\n",
            "    accuracy                           0.97    328708\n",
            "   macro avg       0.76      0.62      0.66    328708\n",
            "weighted avg       0.97      0.97      0.97    328708\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHskwYHXi3V7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a53b49b4-7c89-4be0-eb95-d3e3a4bb9332"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "X = df.drop('Tag', axis=1)\n",
        "v = DictVectorizer()\n",
        "X = v.fit_transform(X.to_dict('records'))\n",
        "y = df.Tag.values\n",
        "classes = np.unique(y)\n",
        "classes = classes.tolist()\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
        "X_train2.shape, y_train2.shape"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((670000, 80141), (670000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-Jd0GYhUpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1388bdcb-0b40-422f-d2e8-b88cbc72ac19"
      },
      "source": [
        "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
        "per.partial_fit(X_train2, y_train2, classes)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "-- Epoch 1\n",
            "Norm: 19.95, NNZs: 371, Bias: -0.400000, T: 670000, Avg. loss: 0.000468\n",
            "Total training time: 0.37 seconds.\n",
            "Norm: 25.87, NNZs: 627, Bias: -0.370000, T: 670000, Avg. loss: 0.000571\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 1\n",
            "-- Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.4s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Norm: 58.25, NNZs: 2545, Bias: -0.570000, T: 670000, Avg. loss: 0.002963\n",
            "Total training time: 0.29 seconds.\n",
            "Norm: 128.81, NNZs: 13303, Bias: -0.640000, T: 670000, Avg. loss: 0.021088\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 1\n",
            "-- Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Norm: 16.25, NNZs: 242, Bias: -0.300000, T: 670000, Avg. loss: 0.000317\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 119.58, NNZs: 11971, Bias: -0.640000, T: 670000, Avg. loss: 0.021285\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 103.74, NNZs: 8981, Bias: -0.570000, T: 670000, Avg. loss: 0.012600\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 87.74, NNZs: 6362, Bias: -0.640000, T: 670000, Avg. loss: 0.012379\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 21.47, NNZs: 416, Bias: -0.430000, T: 670000, Avg. loss: 0.000435\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Norm: 19.60, NNZs: 333, Bias: -0.340000, T: 670000, Avg. loss: 0.000401\n",
            "Total training time: 0.36 seconds.\n",
            "Norm: 73.51, NNZs: 4610, Bias: -0.590000, T: 670000, Avg. loss: 0.006807\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 1\n",
            "-- Epoch 1\n",
            "Norm: 15.39, NNZs: 217, Bias: -0.270000, T: 670000, Avg. loss: 0.000269\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 9.54, NNZs: 85, Bias: -0.190000, T: 670000, Avg. loss: 0.000084\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 115.93, NNZs: 10715, Bias: -0.650000, T: 670000, Avg. loss: 0.012526\n",
            "Total training time: 0.27 seconds.\n",
            "Norm: 110.90, NNZs: 9440, Bias: -0.710000, T: 670000, Avg. loss: 0.016277\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 1\n",
            "-- Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    2.5s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Norm: 76.79, NNZs: 4863, Bias: -0.720000, T: 670000, Avg. loss: 0.010360\n",
            "Total training time: 0.27 seconds.\n",
            "Norm: 145.70, NNZs: 15506, Bias: 0.600000, T: 670000, Avg. loss: 0.031883\n",
            "Total training time: 0.29 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
              "           fit_intercept=True, max_iter=5, n_iter_no_change=5, n_jobs=-1,\n",
              "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
              "           validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bea70MdQj-dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}